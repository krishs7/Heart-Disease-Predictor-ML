{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/Shared with me/CAPSTONE/Colab/Final/cleve.csv')"],"metadata":{"id":"a17yJZf3Sgdh","colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"status":"error","timestamp":1744323371382,"user_tz":240,"elapsed":50,"user":{"displayName":"Karishab Sharma","userId":"14160105575990006809"}},"outputId":"c5d04335-8092-42e3-a414-fd85e6ca393e"},"id":"a17yJZf3Sgdh","execution_count":10,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Mountpoint must not contain a space.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-c31059d8bb8c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shared with me/CAPSTONE/Colab/Final/cleve.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not contain a space.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VERTEX_PRODUCT'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'COLAB_ENTERPRISE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Mountpoint must not contain a space."]}]},{"cell_type":"code","execution_count":null,"id":"1a2e6bd3","metadata":{"id":"1a2e6bd3"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    log_loss, mean_squared_error, accuracy_score,\n","    confusion_matrix, classification_report, roc_auc_score,\n","    roc_curve, recall_score\n",")\n","from sklearn.utils import resample\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","\n","\n","class LogisticRegr:\n","    def __init__(self, log_loss=True):\n","        self.use_log_loss = log_loss\n","        self.model = LogisticRegression(penalty=\"l2\", solver='liblinear')\n","        self.flag = False\n","        self.flag_y_pred = None\n","\n","    def fit(self, X, y):\n","        y_unique = np.unique(y)\n","        if len(y_unique) == 1:\n","            self.flag = True\n","            self.flag_y_pred = y_unique[0]\n","        else:\n","            self.model.fit(X, y)\n","\n","    def predict(self, X):\n","        if self.flag:\n","            return np.full(len(X), self.flag_y_pred, dtype=int)\n","        else:\n","            return self.model.predict(X)\n","\n","    def predict_proba(self, X):\n","        X = np.array(X)\n","        if X.ndim == 1:\n","            X = X.reshape(1, -1)\n","\n","        if self.flag:\n","            proba = np.zeros((len(X), 2))\n","            proba[:, int(self.flag_y_pred)] = 1.0\n","            return proba\n","        else:\n","            return self.model.predict_proba(X)\n","\n","    def loss(self, y, y_pred_proba_or_class):\n","        if self.use_log_loss:\n","            return log_loss(y, y_pred_proba_or_class, labels=[0, 1])\n","        else:\n","            return mean_squared_error(y, y_pred_proba_or_class)\n","\n","\n","class ModelTree:\n","    def __init__(self, model, max_depth=5, min_samples_leaf=10, log_loss=True, verbose=True):\n","        self.model = model\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.verbose = verbose\n","        self.log_loss = log_loss\n","        self.tree = None\n","\n","    def fit(self, X, y):\n","        self.tree = self._build_tree(X, y)\n","        return self.tree\n","\n","    def predict(self, X):\n","        assert self.tree is not None, \"ModelTree not fitted\"\n","        return np.array([self._predict_node(self.tree, x) for x in X])\n","\n","    def predict_proba(self, X):\n","        assert self.tree is not None, \"ModelTree not fitted\"\n","        probas = np.array([self._proba_node(self.tree, x) for x in X])\n","        if probas.ndim == 1:\n","            probas = np.column_stack([1 - probas, probas])\n","        return probas\n","\n","    def _build_tree(self, X, y, depth=0, container=None):\n","        if container is None:\n","            container = {\"index_node_global\": 0}\n","\n","        node = self._create_node(X, y, depth, container)\n","\n","        if depth >= self.max_depth or len(X) <= self.min_samples_leaf:\n","            if self.verbose:\n","                self._print_node(node, depth)\n","            return node\n","\n","        split_result = self._split_node(node)\n","\n","        if not split_result[\"did_split\"]:\n","            if self.verbose:\n","                self._print_node(node, depth)\n","            return node\n","\n","        node.update({\n","            \"j_feature\": split_result[\"j_feature\"],\n","            \"threshold\": split_result[\"threshold\"],\n","            \"children\": {\n","                \"left\": self._build_tree(*split_result[\"data\"][0], depth + 1, container),\n","                \"right\": self._build_tree(*split_result[\"data\"][1], depth + 1, container)\n","            }\n","        })\n","\n","        return node\n","\n","    def _fit_model(self, X, y):\n","        model = self.model(log_loss=self.log_loss)\n","        model.fit(X, y)\n","        preds = model.predict_proba(X) if self.log_loss else model.predict(X)\n","        loss = model.loss(y, preds)\n","        return loss, model\n","\n","    def _create_node(self, X, y, depth, container):\n","        loss, model = self._fit_model(X, y)\n","\n","        node = {\n","            'name': 'node',\n","            'index': container['index_node_global'],\n","            'loss': loss,\n","            'model': model,\n","            'data': (X, y),\n","            'n_samples': len(X),\n","            'j_feature': None,\n","            'threshold': None,\n","            'children': {\n","                'left': None,\n","                'right': None\n","            },\n","            'depth': depth\n","        }\n","\n","        container[\"index_node_global\"] += 1\n","        return node\n","\n","    def _split_data(self, feature, X, y, threshold):\n","        left_idx = np.where(X[:, feature] <= threshold)[0]\n","        right_idx = np.setdiff1d(np.arange(len(X)), left_idx)\n","\n","        left_X, left_y = X[left_idx], y[left_idx]\n","        right_X, right_y = X[right_idx], y[right_idx]\n","\n","        return left_X, left_y, right_X, right_y\n","\n","    def _split_node(self, node):\n","        X, y = node[\"data\"]\n","        depth = node[\"depth\"]\n","        N, d = X.shape\n","\n","        best_split = {\n","            \"did_split\": False,\n","            \"loss\": node[\"loss\"],\n","            \"data\": None,\n","            \"j_feature\": None,\n","            \"threshold\": None,\n","            \"N\": N\n","        }\n","\n","        if depth >= self.max_depth:\n","            return best_split\n","\n","        for j_feature in range(d):\n","            thresholds = np.unique(X[:, j_feature])\n","\n","            for threshold in thresholds:\n","                X_left, y_left, X_right, y_right = self._split_data(j_feature, X, y, threshold)\n","\n","                if (len(X_left) < self.min_samples_leaf or len(X_right) < self.min_samples_leaf):\n","                    continue\n","\n","                left_loss, _ = self._fit_model(X_left, y_left)\n","                right_loss, _ = self._fit_model(X_right, y_right)\n","                loss_split = (len(X_left)*left_loss + len(X_right)*right_loss) / N\n","\n","                if loss_split < best_split[\"loss\"]:\n","                    best_split.update({\n","                        \"did_split\": True,\n","                        \"loss\": loss_split,\n","                        \"data\": [(X_left, y_left), (X_right, y_right)],\n","                        \"j_feature\": j_feature,\n","                        \"threshold\": threshold,\n","                    })\n","\n","        return best_split\n","\n","    def _predict_node(self, node, x):\n","        if node[\"children\"][\"left\"] is None and node[\"children\"][\"right\"] is None:\n","            return node[\"model\"].predict(x.reshape(1, -1))[0]\n","\n","        feature = node[\"j_feature\"]\n","        threshold = node[\"threshold\"]\n","\n","        if x[feature] < threshold:\n","            return self._predict_node(node[\"children\"][\"left\"], x)\n","        else:\n","            return self._predict_node(node[\"children\"][\"right\"], x)\n","\n","    def _proba_node(self, node, x):\n","        if node[\"children\"][\"left\"] is None and node[\"children\"][\"right\"] is None:\n","            return node[\"model\"].predict_proba(x.reshape(1, -1))[0]\n","\n","        feature = node[\"j_feature\"]\n","        threshold = node[\"threshold\"]\n","\n","        if x[feature] < threshold:\n","            return self._proba_node(node[\"children\"][\"left\"], x)\n","        else:\n","            return self._proba_node(node[\"children\"][\"right\"], x)\n","\n","    def _print_node(self, node, depth):\n","        print(f\"Depth: {depth}, Node Index: {node['index']}, Loss: {node['loss']}, Samples: {node['n_samples']}\")\n","\n","\n","class EnhancedModelForest(BaseEstimator, ClassifierMixin):\n","    def __init__(self, model, n_trees=10, max_depth=5, min_samples_leaf=10,\n","                 verbose=True, max_features=\"sqrt\", boosting=False, learning_rate=0.1, log_loss=True):\n","        self.model = model\n","        self.n_trees = n_trees\n","        self.max_depth = max_depth\n","        self.min_samples_leaf = min_samples_leaf\n","        self.verbose = verbose\n","        self.max_features = max_features\n","        self.boosting = boosting\n","        self.learning_rate = learning_rate\n","        self.log_loss = log_loss\n","        self.trees = []\n","        self.tree_weights = []\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","\n","        if self.max_features == \"sqrt\":\n","            self.n_features = int(np.sqrt(n_features))\n","        elif self.max_features == \"log2\":\n","            self.n_features = int(np.log2(n_features))\n","        elif isinstance(self.max_features, int):\n","            self.n_features = self.max_features\n","        else:\n","            raise ValueError(\"max_features must be 'sqrt', 'log2', or an integer.\")\n","\n","        self.trees = []\n","        self.tree_weights = []\n","\n","        if not self.boosting:\n","            for i in range(self.n_trees):\n","                if self.verbose:\n","                    print(f\"Building bagged tree {i + 1}/{self.n_trees}\")\n","                X_sample, y_sample = resample(X, y, replace=True)\n","                tree = ModelTree(\n","                    model=self.model,\n","                    max_depth=self.max_depth,\n","                    min_samples_leaf=self.min_samples_leaf,\n","                    verbose=self.verbose,\n","                    log_loss=self.log_loss\n","                )\n","                tree.fit(X_sample, y_sample)\n","                self.trees.append(tree)\n","                self.tree_weights.append(1.0)\n","        else:\n","            sample_weights = np.ones(len(y)) / len(y)\n","            for i in range(self.n_trees):\n","                if self.verbose:\n","                    print(f\"Building boosted tree {i + 1}/{self.n_trees}\")\n","                X_sample, y_sample, sample_weights_sampled = self._boost_sample(X, y, sample_weights)\n","                tree = ModelTree(\n","                    model=self.model,\n","                    max_depth=self.max_depth,\n","                    min_samples_leaf=self.min_samples_leaf,\n","                    verbose=self.verbose,\n","                    log_loss=self.log_loss\n","                )\n","                tree.fit(X_sample, y_sample)\n","                preds = tree.predict(X)\n","                incorrect = (preds != y)\n","                error = np.sum(sample_weights * incorrect) / np.sum(sample_weights)\n","                if error > 0.5:\n","                    if self.verbose:\n","                        print(f\"Discarding tree {i+1} with error {error:.4f}\")\n","                    continue\n","                elif error == 0:\n","                    tree_weight = 1.0\n","                else:\n","                    tree_weight = self.learning_rate * np.log((1 - error) / error)\n","                sample_weights *= np.exp(tree_weight * incorrect)\n","                sample_weights /= np.sum(sample_weights)\n","                self.trees.append(tree)\n","                self.tree_weights.append(tree_weight)\n","\n","    def _boost_sample(self, X, y, sample_weights):\n","        indices = np.random.choice(len(X), size=len(X), replace=True, p=sample_weights)\n","        return X[indices], y[indices], sample_weights[indices]\n","\n","    def predict(self, X):\n","        if not self.trees:\n","            raise ValueError(\"Model not fitted yet.\")\n","        if not self.boosting:\n","            predictions = np.array([tree.predict(X) for tree in self.trees])\n","            return np.round(np.mean(predictions, axis=0)).astype(int)\n","        else:\n","            predictions = np.array([tree.predict(X) for tree in self.trees])\n","            weights = np.array(self.tree_weights).reshape(-1, 1)\n","            weighted_pred = np.sum(predictions * weights, axis=0) / np.sum(weights)\n","            return np.round(weighted_pred).astype(int)\n","\n","    def predict_proba(self, X):\n","        if not self.trees:\n","            raise ValueError(\"Model not fitted yet.\")\n","        if not self.boosting:\n","            probas = np.array([tree.predict_proba(X) for tree in self.trees])\n","            return np.mean(probas, axis=0)\n","        else:\n","            probas = np.array([tree.predict_proba(X) for tree in self.trees])\n","            weights = np.array(self.tree_weights).reshape(-1, 1, 1)\n","            weighted_proba = np.sum(probas * weights, axis=0) / np.sum(weights)\n","            return weighted_proba\n","\n","    def score(self, X, y):\n","        y_pred = self.predict(X)\n","        return accuracy_score(y, y_pred)\n","\n","    def loss(self, y, y_pred_or_proba):\n","        if self.log_loss:\n","            return log_loss(y, y_pred_or_proba, labels=[0, 1])\n","        else:\n","            return mean_squared_error(y, y_pred_or_proba)\n"]},{"cell_type":"code","execution_count":null,"id":"bca8c57d","metadata":{"id":"bca8c57d","colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"status":"error","timestamp":1744317497665,"user_tz":240,"elapsed":16,"user":{"displayName":"Karishab Sharma","userId":"14160105575990006809"}},"outputId":"c5209692-92b3-40df-ca52-eafcd3da0a71"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-180e0ceeebd0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CAPSTONE/Colab/Final/cleve.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["dataset = pd.read_csv('/content/drive/MyDrive/CAPSTONE/Colab/Final/cleve.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","X[:, 11:13] = imputer.fit_transform(X[:, 11:13])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)"]},{"cell_type":"code","execution_count":null,"id":"c83a7171","metadata":{"id":"c83a7171","outputId":"feaf8690-95d7-42ca-b543-1cd0d34e021b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Building boosted tree 1/17\n","Depth: 3, Node Index: 3, Loss: 0.1638271133139882, Samples: 20\n","Depth: 3, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 4, Node Index: 7, Loss: 0.07120887328449989, Samples: 13\n","Depth: 4, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 40\n","Depth: 4, Node Index: 10, Loss: 0.12219408203463303, Samples: 16\n","Depth: 4, Node Index: 11, Loss: 0.05972722924935247, Samples: 13\n","Depth: 4, Node Index: 15, Loss: 0.09398392445150706, Samples: 17\n","Depth: 4, Node Index: 16, Loss: 0.06958602709076306, Samples: 18\n","Depth: 5, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 5, Node Index: 20, Loss: 0.09487955710031278, Samples: 21\n","Depth: 4, Node Index: 21, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 3, Node Index: 23, Loss: 0.10319895565659981, Samples: 12\n","Depth: 3, Node Index: 24, Loss: 0.07764695512290512, Samples: 20\n","Building boosted tree 2/17\n","Depth: 4, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 25\n","Depth: 4, Node Index: 5, Loss: 0.06634906867251093, Samples: 13\n","Depth: 5, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 37\n","Depth: 5, Node Index: 9, Loss: 0.14630151722857485, Samples: 13\n","Depth: 4, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 2, Node Index: 11, Loss: 0.15045592855725387, Samples: 21\n","Depth: 3, Node Index: 14, Loss: 0.13537560116085945, Samples: 12\n","Depth: 3, Node Index: 15, Loss: 0.11917168149627172, Samples: 15\n","Depth: 4, Node Index: 18, Loss: 0.08506707794254685, Samples: 19\n","Depth: 5, Node Index: 20, Loss: 0.07145794623147886, Samples: 21\n","Depth: 5, Node Index: 21, Loss: 2.2204460492503136e-16, Samples: 20\n","Depth: 3, Node Index: 22, Loss: 0.11121225030361023, Samples: 14\n","Building boosted tree 3/17\n","Depth: 4, Node Index: 4, Loss: 0.16064963802301319, Samples: 16\n","Depth: 5, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 19\n","Depth: 5, Node Index: 7, Loss: 0.07749864212740278, Samples: 14\n","Depth: 5, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 18\n","Depth: 5, Node Index: 11, Loss: 0.06721792902637226, Samples: 41\n","Depth: 4, Node Index: 12, Loss: 0.05561511949695185, Samples: 15\n","Depth: 3, Node Index: 14, Loss: 0.1843539575186942, Samples: 15\n","Depth: 4, Node Index: 16, Loss: 0.06672001099536595, Samples: 13\n","Depth: 4, Node Index: 17, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 3, Node Index: 20, Loss: 0.09210242963165677, Samples: 19\n","Depth: 3, Node Index: 21, Loss: 0.07169700319631529, Samples: 14\n","Depth: 3, Node Index: 23, Loss: 0.16339169697038988, Samples: 12\n","Depth: 3, Node Index: 24, Loss: 0.08799910561757308, Samples: 14\n","Building boosted tree 4/17\n","Depth: 3, Node Index: 3, Loss: 0.09201058935800437, Samples: 17\n","Depth: 4, Node Index: 5, Loss: 0.12450869027952408, Samples: 18\n","Depth: 4, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 4, Node Index: 9, Loss: 0.06915723806253153, Samples: 15\n","Depth: 4, Node Index: 10, Loss: 0.06365689757440794, Samples: 14\n","Depth: 5, Node Index: 13, Loss: 0.09407650718541674, Samples: 26\n","Depth: 5, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 14\n","Depth: 4, Node Index: 15, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 4, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 5, Node Index: 21, Loss: 0.11546623024815274, Samples: 18\n","Depth: 5, Node Index: 22, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 3, Node Index: 23, Loss: 0.06639723777213626, Samples: 17\n","Depth: 3, Node Index: 25, Loss: 0.12351923226574273, Samples: 12\n","Depth: 3, Node Index: 26, Loss: 0.08402684843519626, Samples: 18\n","Building boosted tree 5/17\n","Depth: 5, Node Index: 5, Loss: 2.2204460492503136e-16, Samples: 26\n","Depth: 5, Node Index: 6, Loss: 0.07856539114048346, Samples: 15\n","Depth: 4, Node Index: 7, Loss: 0.12432838164296192, Samples: 17\n","Depth: 3, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 42\n","Depth: 3, Node Index: 10, Loss: 0.07026883699003242, Samples: 14\n","Depth: 3, Node Index: 11, Loss: 0.0771731054199704, Samples: 13\n","Depth: 4, Node Index: 15, Loss: 0.09932448308817737, Samples: 20\n","Depth: 4, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 23\n","Depth: 3, Node Index: 17, Loss: 0.07121332693140468, Samples: 12\n","Depth: 3, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 22\n","Depth: 3, Node Index: 20, Loss: 0.11008002106668491, Samples: 23\n","Building boosted tree 6/17\n","Depth: 3, Node Index: 3, Loss: 0.13056228498144082, Samples: 21\n","Depth: 4, Node Index: 5, Loss: 2.2204460492503136e-16, Samples: 26\n","Depth: 4, Node Index: 6, Loss: 0.0792649394101364, Samples: 12\n","Depth: 4, Node Index: 9, Loss: 0.11143493840968909, Samples: 14\n","Depth: 4, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 3, Node Index: 11, Loss: 0.0721256378109487, Samples: 17\n","Depth: 5, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 29\n","Depth: 5, Node Index: 17, Loss: 0.06922967189451264, Samples: 17\n","Depth: 4, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 4, Node Index: 20, Loss: 0.11030842467621695, Samples: 14\n","Depth: 4, Node Index: 21, Loss: 0.09645953642700622, Samples: 16\n","Depth: 3, Node Index: 23, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 3, Node Index: 24, Loss: 0.09437417795083544, Samples: 15\n","Building boosted tree 7/17\n","Depth: 5, Node Index: 5, Loss: 0.05776338102141685, Samples: 19\n","Depth: 5, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 50\n","Depth: 4, Node Index: 7, Loss: 0.08046708388460681, Samples: 14\n","Depth: 4, Node Index: 9, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 4, Node Index: 10, Loss: 0.08485287350822902, Samples: 16\n","Depth: 4, Node Index: 13, Loss: 0.08920165145538247, Samples: 15\n","Depth: 4, Node Index: 14, Loss: 0.12704871259949554, Samples: 12\n","Depth: 4, Node Index: 16, Loss: 0.0514664573131404, Samples: 13\n","Depth: 4, Node Index: 17, Loss: 2.2204460492503136e-16, Samples: 22\n","Depth: 3, Node Index: 20, Loss: 0.06749147403811157, Samples: 22\n","Depth: 3, Node Index: 21, Loss: 0.06658817621512583, Samples: 15\n","Depth: 2, Node Index: 22, Loss: 0.10924312908927063, Samples: 17\n","Building boosted tree 8/17\n","Depth: 4, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 5, Loss: 0.09061571908880495, Samples: 18\n","Depth: 3, Node Index: 6, Loss: 0.11551744580379489, Samples: 15\n","Depth: 5, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 5, Node Index: 11, Loss: 0.05980053690930742, Samples: 16\n","Depth: 4, Node Index: 12, Loss: 0.13131679445842626, Samples: 15\n","Depth: 4, Node Index: 14, Loss: 0.0658287866251399, Samples: 15\n","Depth: 5, Node Index: 16, Loss: 0.1660362912321077, Samples: 13\n","Depth: 5, Node Index: 17, Loss: 0.06475397254010208, Samples: 13\n","Depth: 4, Node Index: 21, Loss: 0.06388869402251374, Samples: 13\n","Depth: 4, Node Index: 22, Loss: 2.2204460492503136e-16, Samples: 24\n","Depth: 3, Node Index: 23, Loss: 0.09875407246077239, Samples: 14\n","Depth: 4, Node Index: 26, Loss: 0.07355791270777468, Samples: 17\n","Depth: 4, Node Index: 27, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 3, Node Index: 28, Loss: 2.2204460492503136e-16, Samples: 12\n","Building boosted tree 9/17\n","Depth: 3, Node Index: 3, Loss: 0.10713546381616122, Samples: 18\n","Depth: 4, Node Index: 5, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 4, Node Index: 6, Loss: 0.09182357690798419, Samples: 12\n","Depth: 4, Node Index: 9, Loss: 0.14162792560105178, Samples: 13\n","Depth: 4, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 14\n","Depth: 5, Node Index: 13, Loss: 2.2204460492503136e-16, Samples: 25\n","Depth: 5, Node Index: 14, Loss: 0.04859172977256232, Samples: 14\n","Depth: 4, Node Index: 15, Loss: 0.0889348756628353, Samples: 20\n","Depth: 3, Node Index: 18, Loss: 0.10395562033939866, Samples: 13\n","Depth: 4, Node Index: 20, Loss: 0.1371571753796699, Samples: 12\n","Depth: 5, Node Index: 22, Loss: 0.0958788688666688, Samples: 16\n","Depth: 5, Node Index: 23, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 3, Node Index: 25, Loss: 0.10662415892360848, Samples: 12\n","Depth: 4, Node Index: 27, Loss: 0.04988957846445756, Samples: 13\n","Depth: 4, Node Index: 28, Loss: 2.2204460492503136e-16, Samples: 17\n","Building boosted tree 10/17\n","Depth: 3, Node Index: 3, Loss: 2.2204460492503136e-16, Samples: 32\n","Depth: 4, Node Index: 5, Loss: 0.10371628488120044, Samples: 16\n","Depth: 4, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 9, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 10, Loss: 0.14486596734632523, Samples: 19\n","Depth: 4, Node Index: 12, Loss: 0.07910161179689508, Samples: 14\n","Depth: 5, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 5, Node Index: 15, Loss: 0.11393657438278604, Samples: 12\n","Depth: 4, Node Index: 19, Loss: 0.09598237175171327, Samples: 17\n","Depth: 4, Node Index: 20, Loss: 0.07993665107141605, Samples: 15\n","Depth: 3, Node Index: 21, Loss: 0.07216213979396026, Samples: 13\n","Depth: 3, Node Index: 23, Loss: 0.048854265071982074, Samples: 17\n","Depth: 3, Node Index: 24, Loss: 2.2204460492503136e-16, Samples: 27\n","Building boosted tree 11/17\n","Depth: 5, Node Index: 5, Loss: 0.09913330571902813, Samples: 15\n","Depth: 5, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 4, Node Index: 7, Loss: 2.2204460492503136e-16, Samples: 39\n","Depth: 3, Node Index: 8, Loss: 0.08615055602737147, Samples: 15\n","Depth: 4, Node Index: 11, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 4, Node Index: 12, Loss: 0.09263992509314091, Samples: 19\n","Depth: 3, Node Index: 13, Loss: 0.06418904002830551, Samples: 21\n","Depth: 3, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 3, Node Index: 17, Loss: 0.16421038121041145, Samples: 22\n","Depth: 3, Node Index: 19, Loss: 0.14768189640096213, Samples: 17\n","Depth: 4, Node Index: 21, Loss: 0.08387642022733895, Samples: 14\n","Depth: 4, Node Index: 22, Loss: 2.2204460492503136e-16, Samples: 15\n","Building boosted tree 12/17\n","Depth: 2, Node Index: 2, Loss: 0.10696040924518622, Samples: 18\n","Depth: 3, Node Index: 4, Loss: 0.10694014998221217, Samples: 20\n","Depth: 4, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 4, Node Index: 7, Loss: 0.0864439196283512, Samples: 27\n","Depth: 5, Node Index: 12, Loss: 0.10947728564569667, Samples: 13\n","Depth: 5, Node Index: 13, Loss: 0.08631510741262301, Samples: 14\n","Depth: 4, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 43\n","Depth: 3, Node Index: 15, Loss: 0.11409123662304639, Samples: 24\n","Depth: 5, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 5, Node Index: 20, Loss: 0.10083791662100793, Samples: 13\n","Depth: 4, Node Index: 21, Loss: 2.2204460492503136e-16, Samples: 14\n","Depth: 3, Node Index: 22, Loss: 0.06952765033275003, Samples: 12\n","Building boosted tree 13/17\n","Depth: 3, Node Index: 3, Loss: 0.2130695285118611, Samples: 22\n","Depth: 4, Node Index: 5, Loss: 0.0603454913520304, Samples: 12\n","Depth: 4, Node Index: 6, Loss: 0.08011394564173774, Samples: 22\n","Depth: 4, Node Index: 9, Loss: 2.2204460492503136e-16, Samples: 31\n","Depth: 4, Node Index: 10, Loss: 0.09910439409839375, Samples: 13\n","Depth: 3, Node Index: 11, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 3, Node Index: 14, Loss: 0.09615251669326558, Samples: 22\n","Depth: 4, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 30\n","Depth: 4, Node Index: 17, Loss: 0.13386728792737707, Samples: 13\n","Depth: 4, Node Index: 20, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 21, Loss: 0.07851814338745902, Samples: 20\n","Depth: 3, Node Index: 22, Loss: 0.08956418282804786, Samples: 12\n","Building boosted tree 14/17\n","Depth: 4, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 4, Node Index: 5, Loss: 0.11697569263489943, Samples: 13\n","Depth: 3, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 23\n","Depth: 3, Node Index: 8, Loss: 0.13023632811210598, Samples: 13\n","Depth: 3, Node Index: 9, Loss: 0.12917886647406718, Samples: 16\n","Depth: 5, Node Index: 14, Loss: 0.06761255030973813, Samples: 21\n","Depth: 5, Node Index: 15, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 4, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 19\n","Depth: 5, Node Index: 20, Loss: 0.07657025488543405, Samples: 15\n","Depth: 5, Node Index: 21, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 3, Node Index: 23, Loss: 2.2204460492503136e-16, Samples: 20\n","Depth: 4, Node Index: 25, Loss: 0.10044746095638077, Samples: 18\n","Depth: 4, Node Index: 26, Loss: 0.10034022931544442, Samples: 14\n","Building boosted tree 15/17\n","Depth: 4, Node Index: 4, Loss: 0.07557228619718599, Samples: 18\n","Depth: 4, Node Index: 5, Loss: 0.07638613144088387, Samples: 24\n","Depth: 4, Node Index: 7, Loss: 2.2204460492503136e-16, Samples: 12\n","Depth: 4, Node Index: 8, Loss: 0.14328968036916617, Samples: 14\n","Depth: 4, Node Index: 11, Loss: 0.0735948193008717, Samples: 15\n","Depth: 4, Node Index: 12, Loss: 0.07057721216112443, Samples: 12\n","Depth: 4, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 4, Node Index: 15, Loss: 0.08461589045976593, Samples: 18\n","Depth: 3, Node Index: 18, Loss: 0.14000182315815266, Samples: 17\n","Depth: 4, Node Index: 20, Loss: 0.08084645187338832, Samples: 20\n","Depth: 4, Node Index: 21, Loss: 0.056891019077868976, Samples: 13\n","Depth: 3, Node Index: 23, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 4, Node Index: 25, Loss: 0.07909846408398118, Samples: 14\n","Depth: 4, Node Index: 26, Loss: 2.2204460492503136e-16, Samples: 24\n","Building boosted tree 16/17\n","Depth: 4, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 31\n","Depth: 5, Node Index: 6, Loss: 0.099814918151621, Samples: 13\n","Depth: 5, Node Index: 7, Loss: 2.2204460492503136e-16, Samples: 14\n","Depth: 3, Node Index: 8, Loss: 0.07274281494556065, Samples: 25\n","Depth: 3, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 3, Node Index: 11, Loss: 0.1605382439126621, Samples: 12\n","Depth: 3, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 25\n","Depth: 3, Node Index: 15, Loss: 0.053524996497870736, Samples: 21\n","Depth: 4, Node Index: 18, Loss: 0.08612741252821635, Samples: 16\n","Depth: 5, Node Index: 20, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 5, Node Index: 21, Loss: 0.13038383195726008, Samples: 12\n","Depth: 3, Node Index: 22, Loss: 0.12177944561828821, Samples: 20\n","Building boosted tree 17/17\n","Depth: 3, Node Index: 3, Loss: 0.08275710215308443, Samples: 12\n","Depth: 3, Node Index: 4, Loss: 0.12923172378172423, Samples: 12\n","Depth: 3, Node Index: 6, Loss: 0.11709047740400268, Samples: 17\n","Depth: 3, Node Index: 7, Loss: 0.0855358101939957, Samples: 21\n","Depth: 4, Node Index: 11, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 5, Node Index: 13, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 5, Node Index: 14, Loss: 0.060997305947668855, Samples: 12\n","Depth: 4, Node Index: 16, Loss: 0.10569865690406188, Samples: 12\n","Depth: 4, Node Index: 17, Loss: 2.2204460492503136e-16, Samples: 27\n","Depth: 4, Node Index: 20, Loss: 2.2204460492503136e-16, Samples: 24\n","Depth: 4, Node Index: 21, Loss: 0.09785773252591719, Samples: 17\n","Depth: 4, Node Index: 23, Loss: 2.2204460492503136e-16, Samples: 13\n","Depth: 4, Node Index: 24, Loss: 0.10286225925881153, Samples: 18\n","Building boosted tree 1/15\n","Depth: 3, Node Index: 3, Loss: 0.15782093426302707, Samples: 23\n","Depth: 3, Node Index: 4, Loss: 0.11704588980077911, Samples: 24\n","Depth: 3, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 26\n","Depth: 3, Node Index: 7, Loss: 0.12244686294748151, Samples: 22\n","Depth: 3, Node Index: 10, Loss: 0.09198817792734972, Samples: 29\n","Depth: 3, Node Index: 11, Loss: 0.0587310637946565, Samples: 19\n","Depth: 3, Node Index: 13, Loss: 2.2204460492503136e-16, Samples: 20\n","Depth: 4, Node Index: 15, Loss: 0.1115797388259313, Samples: 18\n","Depth: 5, Node Index: 17, Loss: 0.1302971370314585, Samples: 27\n","Depth: 5, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 19\n","Building boosted tree 2/15\n","Depth: 3, Node Index: 3, Loss: 0.16415885335317934, Samples: 25\n","Depth: 3, Node Index: 4, Loss: 0.15329993477617143, Samples: 25\n","Depth: 4, Node Index: 7, Loss: 0.045460034718052184, Samples: 17\n","Depth: 4, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 37\n","Depth: 3, Node Index: 9, Loss: 0.08960649370514782, Samples: 26\n","Depth: 3, Node Index: 12, Loss: 0.07215539910142914, Samples: 19\n","Depth: 3, Node Index: 13, Loss: 0.15048283891922568, Samples: 19\n","Depth: 3, Node Index: 15, Loss: 0.059816803708152136, Samples: 17\n","Depth: 3, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 42\n","Building boosted tree 3/15\n","Depth: 4, Node Index: 4, Loss: 0.15713391266600685, Samples: 16\n","Depth: 4, Node Index: 5, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 4, Node Index: 7, Loss: 0.09158776470074173, Samples: 18\n","Depth: 4, Node Index: 8, Loss: 0.07773877338915482, Samples: 24\n","Depth: 4, Node Index: 11, Loss: 0.07760727307492449, Samples: 22\n","Depth: 5, Node Index: 13, Loss: 0.04912103655024011, Samples: 17\n","Depth: 6, Node Index: 15, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 6, Node Index: 16, Loss: 0.0864582663532239, Samples: 15\n","Depth: 3, Node Index: 17, Loss: 0.10396724688114956, Samples: 25\n","Depth: 3, Node Index: 20, Loss: 0.07468135370373545, Samples: 16\n","Depth: 3, Node Index: 21, Loss: 0.0659439277130836, Samples: 16\n","Depth: 2, Node Index: 22, Loss: 0.08178854106754449, Samples: 26\n","Building boosted tree 4/15\n","Depth: 3, Node Index: 3, Loss: 0.13504801456394622, Samples: 17\n","Depth: 3, Node Index: 4, Loss: 0.08180271114484967, Samples: 18\n","Depth: 3, Node Index: 6, Loss: 0.11514123707444554, Samples: 29\n","Depth: 4, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 37\n","Depth: 4, Node Index: 9, Loss: 0.14364695826133975, Samples: 22\n","Depth: 3, Node Index: 12, Loss: 2.2204460492503136e-16, Samples: 54\n","Depth: 3, Node Index: 13, Loss: 0.10321882812744115, Samples: 15\n","Depth: 3, Node Index: 15, Loss: 0.1794545847588475, Samples: 20\n","Depth: 3, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 15\n","Building boosted tree 5/15\n","Depth: 2, Node Index: 2, Loss: 0.2184995729277288, Samples: 27\n","Depth: 4, Node Index: 5, Loss: 0.05010167614601211, Samples: 22\n","Depth: 4, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 28\n","Depth: 3, Node Index: 7, Loss: 0.07806812369812653, Samples: 26\n","Depth: 4, Node Index: 11, Loss: 0.10047547427864595, Samples: 26\n","Depth: 4, Node Index: 12, Loss: 0.1706356755859019, Samples: 24\n","Depth: 3, Node Index: 13, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 3, Node Index: 15, Loss: 0.17211106313606298, Samples: 25\n","Depth: 3, Node Index: 16, Loss: 0.08343687746986779, Samples: 28\n","Building boosted tree 6/15\n","Depth: 3, Node Index: 3, Loss: 0.042473943194077275, Samples: 30\n","Depth: 3, Node Index: 4, Loss: 0.08727496336508679, Samples: 22\n","Depth: 3, Node Index: 6, Loss: 0.07613658957404293, Samples: 20\n","Depth: 3, Node Index: 7, Loss: 0.04212221218864097, Samples: 28\n","Depth: 4, Node Index: 11, Loss: 2.2204460492503136e-16, Samples: 20\n","Depth: 4, Node Index: 12, Loss: 0.14411845534783263, Samples: 16\n","Depth: 4, Node Index: 14, Loss: 0.11579295670547478, Samples: 19\n","Depth: 4, Node Index: 15, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 3, Node Index: 17, Loss: 0.19438532070445894, Samples: 19\n","Depth: 4, Node Index: 19, Loss: 0.06710755858066463, Samples: 16\n","Depth: 4, Node Index: 20, Loss: 0.08193388789842525, Samples: 16\n","Building boosted tree 7/15\n","Depth: 2, Node Index: 2, Loss: 0.12964928129894815, Samples: 16\n","Depth: 2, Node Index: 3, Loss: 0.1665291289879106, Samples: 15\n","Depth: 3, Node Index: 6, Loss: 0.16641974392718673, Samples: 29\n","Depth: 5, Node Index: 9, Loss: 0.13655458252889002, Samples: 20\n","Depth: 5, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 5, Node Index: 12, Loss: 0.07036562918825057, Samples: 21\n","Depth: 5, Node Index: 13, Loss: 2.2204460492503136e-16, Samples: 24\n","Depth: 3, Node Index: 15, Loss: 0.23895095848741957, Samples: 25\n","Depth: 5, Node Index: 18, Loss: 0.08026695313798717, Samples: 20\n","Depth: 5, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 25\n","Depth: 4, Node Index: 20, Loss: 0.0752120992982575, Samples: 15\n","Building boosted tree 8/15\n","Depth: 3, Node Index: 3, Loss: 0.15324768458217428, Samples: 16\n","Depth: 3, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 19\n","Depth: 3, Node Index: 6, Loss: 0.06471892342654068, Samples: 17\n","Depth: 4, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 19\n","Depth: 4, Node Index: 9, Loss: 0.07674797429556103, Samples: 25\n","Depth: 4, Node Index: 13, Loss: 0.0917462673281639, Samples: 21\n","Depth: 4, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 18\n","Depth: 4, Node Index: 16, Loss: 0.09788236531370595, Samples: 20\n","Depth: 5, Node Index: 18, Loss: 0.07386997531743994, Samples: 16\n","Depth: 5, Node Index: 19, Loss: 0.05615603698680576, Samples: 16\n","Depth: 3, Node Index: 21, Loss: 0.08910551934510118, Samples: 23\n","Depth: 3, Node Index: 22, Loss: 0.1368770504901689, Samples: 17\n","Building boosted tree 9/15\n","Depth: 4, Node Index: 4, Loss: 2.2204460492503136e-16, Samples: 19\n","Depth: 5, Node Index: 6, Loss: 0.0844726068448234, Samples: 15\n","Depth: 5, Node Index: 7, Loss: 0.0893888941896415, Samples: 20\n","Depth: 3, Node Index: 8, Loss: 0.1332183582118065, Samples: 20\n","Depth: 2, Node Index: 9, Loss: 0.1411591792040501, Samples: 27\n","Depth: 4, Node Index: 13, Loss: 0.08516382986670823, Samples: 24\n","Depth: 4, Node Index: 14, Loss: 2.2204460492503136e-16, Samples: 33\n","Depth: 3, Node Index: 15, Loss: 0.08143093431697926, Samples: 17\n","Depth: 4, Node Index: 18, Loss: 0.07288216031054362, Samples: 21\n","Depth: 4, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 16\n","Depth: 3, Node Index: 20, Loss: 0.08988016089474812, Samples: 15\n","Building boosted tree 10/15\n","Depth: 2, Node Index: 2, Loss: 0.20344860916725613, Samples: 24\n","Depth: 5, Node Index: 6, Loss: 0.08888677191893667, Samples: 32\n","Depth: 5, Node Index: 7, Loss: 2.2204460492503136e-16, Samples: 21\n","Depth: 4, Node Index: 8, Loss: 0.13149488939037943, Samples: 18\n","Depth: 4, Node Index: 10, Loss: 0.09845789076440088, Samples: 15\n","Depth: 4, Node Index: 11, Loss: 0.1168618556540353, Samples: 15\n","Depth: 4, Node Index: 15, Loss: 0.07659555346522237, Samples: 16\n","Depth: 4, Node Index: 16, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 3, Node Index: 17, Loss: 0.12210167169253903, Samples: 21\n","Depth: 3, Node Index: 19, Loss: 0.06984906843908338, Samples: 23\n","Depth: 3, Node Index: 20, Loss: 0.07145482951625245, Samples: 27\n","Building boosted tree 11/15\n","Depth: 5, Node Index: 5, Loss: 2.2204460492503136e-16, Samples: 18\n","Depth: 5, Node Index: 6, Loss: 0.09822942462563092, Samples: 22\n","Depth: 4, Node Index: 7, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 3, Node Index: 8, Loss: 0.08195128470529722, Samples: 15\n","Depth: 4, Node Index: 11, Loss: 2.2204460492503136e-16, Samples: 22\n","Depth: 4, Node Index: 12, Loss: 0.0603428587541884, Samples: 15\n","Depth: 4, Node Index: 14, Loss: 0.16913109606005652, Samples: 23\n","Depth: 4, Node Index: 15, Loss: 0.1178125703144144, Samples: 31\n","Depth: 3, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 30\n","Depth: 3, Node Index: 19, Loss: 0.12338201851592617, Samples: 15\n","Depth: 2, Node Index: 20, Loss: 0.109319992347046, Samples: 19\n","Building boosted tree 12/15\n","Depth: 3, Node Index: 3, Loss: 0.10729420336586853, Samples: 26\n","Depth: 3, Node Index: 4, Loss: 0.14930148372994345, Samples: 25\n","Depth: 3, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 25\n","Depth: 3, Node Index: 7, Loss: 0.12303953387937742, Samples: 19\n","Depth: 3, Node Index: 10, Loss: 0.07362060830966022, Samples: 35\n","Depth: 4, Node Index: 12, Loss: 2.2204460492503136e-16, Samples: 18\n","Depth: 4, Node Index: 13, Loss: 0.11760293282601554, Samples: 15\n","Depth: 4, Node Index: 16, Loss: 0.1675222434513899, Samples: 22\n","Depth: 4, Node Index: 17, Loss: 0.10492393144107466, Samples: 27\n","Depth: 3, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 15\n","Building boosted tree 13/15\n","Depth: 3, Node Index: 3, Loss: 0.1276939861105678, Samples: 15\n","Depth: 4, Node Index: 5, Loss: 0.11856296913134717, Samples: 16\n","Depth: 4, Node Index: 6, Loss: 2.2204460492503136e-16, Samples: 43\n","Depth: 3, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 3, Node Index: 9, Loss: 0.16258953427751796, Samples: 25\n","Depth: 4, Node Index: 13, Loss: 0.08886095799935963, Samples: 15\n","Depth: 4, Node Index: 14, Loss: 0.09852627459822487, Samples: 16\n","Depth: 4, Node Index: 16, Loss: 0.0667806789977605, Samples: 15\n","Depth: 4, Node Index: 17, Loss: 0.09070912707866566, Samples: 15\n","Depth: 3, Node Index: 19, Loss: 2.2204460492503136e-16, Samples: 17\n","Depth: 4, Node Index: 21, Loss: 0.09913380500667968, Samples: 17\n","Depth: 4, Node Index: 22, Loss: 0.07778656920446982, Samples: 18\n","Building boosted tree 14/15\n","Depth: 2, Node Index: 2, Loss: 0.11421599654926179, Samples: 16\n","Depth: 2, Node Index: 3, Loss: 0.14107165186717802, Samples: 29\n","Depth: 5, Node Index: 8, Loss: 2.2204460492503136e-16, Samples: 31\n","Depth: 5, Node Index: 9, Loss: 0.14541368117127615, Samples: 18\n","Depth: 4, Node Index: 10, Loss: 2.2204460492503136e-16, Samples: 20\n","Depth: 3, Node Index: 11, Loss: 0.17193916766553435, Samples: 18\n","Depth: 5, Node Index: 15, Loss: 0.1096323468027128, Samples: 15\n","Depth: 5, Node Index: 16, Loss: 0.08292045307637128, Samples: 17\n","Depth: 5, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 15\n","Depth: 5, Node Index: 19, Loss: 0.06040297464277415, Samples: 30\n","Depth: 3, Node Index: 20, Loss: 0.15899324570198103, Samples: 18\n","Building boosted tree 15/15\n","Depth: 5, Node Index: 5, Loss: 0.046074253473051566, Samples: 20\n","Depth: 5, Node Index: 6, Loss: 0.04203661289629875, Samples: 21\n","Depth: 4, Node Index: 7, Loss: 0.06479787724993911, Samples: 23\n","Depth: 4, Node Index: 9, Loss: 0.06543819298113594, Samples: 15\n","Depth: 5, Node Index: 11, Loss: 0.10914172011622668, Samples: 15\n","Depth: 5, Node Index: 12, Loss: 0.07041500995556764, Samples: 17\n","Depth: 3, Node Index: 14, Loss: 0.17008624820342844, Samples: 18\n","Depth: 3, Node Index: 15, Loss: 0.11315587492921789, Samples: 16\n","Depth: 3, Node Index: 18, Loss: 2.2204460492503136e-16, Samples: 50\n","Depth: 3, Node Index: 19, Loss: 0.11096980325028614, Samples: 15\n","Depth: 2, Node Index: 20, Loss: 0.11598988597107728, Samples: 17\n","Building bagged tree 1/9\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 42\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 60\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 26\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 12\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 47\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 40\n","Building bagged tree 2/9\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 18\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 61\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 30\n","Depth: 3, Node Index: 8, Loss: 0.0, Samples: 55\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 10\n","Depth: 2, Node Index: 10, Loss: 0.0, Samples: 53\n","Building bagged tree 3/9\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 28\n","Depth: 4, Node Index: 5, Loss: 0.0, Samples: 70\n","Depth: 4, Node Index: 6, Loss: 0.0, Samples: 75\n","Depth: 3, Node Index: 8, Loss: 0.0, Samples: 11\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 15\n","Depth: 1, Node Index: 10, Loss: 0.0, Samples: 28\n","Building bagged tree 4/9\n","Depth: 2, Node Index: 2, Loss: 0.058823529411764705, Samples: 17\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 69\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 44\n","Depth: 4, Node Index: 8, Loss: 0.0, Samples: 18\n","Depth: 4, Node Index: 9, Loss: 0.0, Samples: 37\n","Depth: 3, Node Index: 11, Loss: 0.0, Samples: 12\n","Depth: 3, Node Index: 12, Loss: 0.0, Samples: 30\n","Building bagged tree 5/9\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 22\n","Depth: 4, Node Index: 5, Loss: 0.0, Samples: 21\n","Depth: 4, Node Index: 6, Loss: 0.0, Samples: 16\n","Depth: 4, Node Index: 9, Loss: 0.0, Samples: 10\n","Depth: 4, Node Index: 10, Loss: 0.0, Samples: 31\n","Depth: 3, Node Index: 11, Loss: 0.0, Samples: 28\n","Depth: 2, Node Index: 13, Loss: 0.0, Samples: 35\n","Depth: 2, Node Index: 14, Loss: 0.0, Samples: 64\n","Building bagged tree 6/9\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 35\n","Depth: 4, Node Index: 5, Loss: 0.0, Samples: 48\n","Depth: 4, Node Index: 6, Loss: 0.0, Samples: 29\n","Depth: 4, Node Index: 8, Loss: 0.0, Samples: 32\n","Depth: 4, Node Index: 9, Loss: 0.0, Samples: 31\n","Depth: 2, Node Index: 11, Loss: 0.0, Samples: 27\n","Depth: 2, Node Index: 12, Loss: 0.0, Samples: 25\n","Building bagged tree 7/9\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 17\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 86\n","Depth: 4, Node Index: 7, Loss: 0.0, Samples: 38\n","Depth: 4, Node Index: 8, Loss: 0.0, Samples: 12\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 45\n","Depth: 2, Node Index: 10, Loss: 0.0, Samples: 29\n","Building bagged tree 8/9\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 10\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 72\n","Depth: 4, Node Index: 7, Loss: 0.0, Samples: 10\n","Depth: 4, Node Index: 8, Loss: 0.0, Samples: 52\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 18\n","Depth: 2, Node Index: 10, Loss: 0.0, Samples: 65\n","Building bagged tree 9/9\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 58\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 40\n","Depth: 3, Node Index: 5, Loss: 0.0, Samples: 58\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 12\n","Depth: 2, Node Index: 8, Loss: 0.0, Samples: 59\n","Building bagged tree 1/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 24\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 26\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 65\n","Depth: 4, Node Index: 9, Loss: 0.0, Samples: 8\n","Depth: 4, Node Index: 10, Loss: 0.0, Samples: 48\n","Depth: 3, Node Index: 11, Loss: 0.0, Samples: 14\n","Depth: 3, Node Index: 13, Loss: 0.0, Samples: 17\n","Depth: 3, Node Index: 14, Loss: 0.0, Samples: 25\n","Building bagged tree 2/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 49\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 80\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 57\n","Depth: 2, Node Index: 6, Loss: 0.0, Samples: 41\n","Building bagged tree 3/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 10\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 39\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 52\n","Depth: 3, Node Index: 8, Loss: 0.0, Samples: 8\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 34\n","Depth: 2, Node Index: 10, Loss: 0.011904761904761904, Samples: 84\n","Building bagged tree 4/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 46\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 55\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 34\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 36\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 11\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 45\n","Building bagged tree 5/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 71\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 9\n","Depth: 3, Node Index: 5, Loss: 0.0, Samples: 37\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 24\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 7\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 79\n","Building bagged tree 6/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 10\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 31\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 30\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 24\n","Depth: 4, Node Index: 10, Loss: 0.0, Samples: 10\n","Depth: 4, Node Index: 11, Loss: 0.0, Samples: 43\n","Depth: 4, Node Index: 13, Loss: 0.0, Samples: 13\n","Depth: 5, Node Index: 15, Loss: 0.0, Samples: 27\n","Depth: 5, Node Index: 16, Loss: 0.0, Samples: 39\n","Building bagged tree 7/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 31\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 51\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 42\n","Depth: 4, Node Index: 8, Loss: 0.0, Samples: 25\n","Depth: 4, Node Index: 9, Loss: 0.0, Samples: 10\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 68\n","Building bagged tree 8/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 61\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 34\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 15\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 27\n","Depth: 2, Node Index: 9, Loss: 0.0, Samples: 55\n","Depth: 2, Node Index: 10, Loss: 0.0, Samples: 35\n","Building bagged tree 9/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 24\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 50\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 42\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 75\n","Depth: 2, Node Index: 8, Loss: 0.0, Samples: 36\n","Building bagged tree 10/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 26\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 83\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 6\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 12\n","Depth: 2, Node Index: 8, Loss: 0.0, Samples: 100\n","Building bagged tree 11/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 20\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 40\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 38\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 40\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 44\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 45\n","Building bagged tree 12/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 27\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 24\n","Depth: 3, Node Index: 6, Loss: 0.0, Samples: 32\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 30\n","Depth: 4, Node Index: 10, Loss: 0.0, Samples: 47\n","Depth: 4, Node Index: 11, Loss: 0.0, Samples: 32\n","Depth: 3, Node Index: 12, Loss: 0.0, Samples: 35\n","Building bagged tree 13/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 68\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 28\n","Depth: 3, Node Index: 5, Loss: 0.0, Samples: 47\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 56\n","Depth: 2, Node Index: 8, Loss: 0.0, Samples: 28\n","Building bagged tree 14/20\n","Depth: 3, Node Index: 3, Loss: 0.0, Samples: 37\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 37\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 39\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 69\n","Depth: 2, Node Index: 8, Loss: 0.0, Samples: 45\n","Building bagged tree 15/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 29\n","Depth: 3, Node Index: 4, Loss: 0.0, Samples: 55\n","Depth: 3, Node Index: 5, Loss: 0.0, Samples: 41\n","Depth: 2, Node Index: 7, Loss: 0.0, Samples: 49\n","Depth: 3, Node Index: 9, Loss: 0.0, Samples: 15\n","Depth: 3, Node Index: 10, Loss: 0.0, Samples: 38\n","Building bagged tree 16/20\n","Depth: 2, Node Index: 2, Loss: 0.0, Samples: 71\n","Depth: 2, Node Index: 3, Loss: 0.0, Samples: 59\n","Depth: 2, Node Index: 5, Loss: 0.0, Samples: 42\n","Depth: 3, Node Index: 7, Loss: 0.0, Samples: 13\n","Depth: 3, Node Index: 8, Loss: 0.0, Samples: 42\n","Building bagged tree 17/20\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_list:\n\u001b[0;32m     35\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     preds \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     38\u001b[0m     score \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, preds)\n","File \u001b[1;32mc:\\Users\\saiko\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","Cell \u001b[1;32mIn[7], line 259\u001b[0m, in \u001b[0;36mEnhancedModelForest.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    251\u001b[0m X_sample, y_sample \u001b[38;5;241m=\u001b[39m resample(X, y, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m tree \u001b[38;5;241m=\u001b[39m ModelTree(\n\u001b[0;32m    253\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    254\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     log_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_loss\n\u001b[0;32m    258\u001b[0m )\n\u001b[1;32m--> 259\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_weights\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.0\u001b[39m)\n","Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36mModelTree.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\n","Cell \u001b[1;32mIn[7], line 103\u001b[0m, in \u001b[0;36mModelTree._build_tree\u001b[1;34m(self, X, y, depth, container)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_node(node, depth)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[0;32m     99\u001b[0m node\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m: split_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: split_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(\u001b[38;5;241m*\u001b[39msplit_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, container)\n\u001b[0;32m    105\u001b[0m     }\n\u001b[0;32m    106\u001b[0m })\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n","Cell \u001b[1;32mIn[7], line 103\u001b[0m, in \u001b[0;36mModelTree._build_tree\u001b[1;34m(self, X, y, depth, container)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_node(node, depth)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[0;32m     99\u001b[0m node\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m: split_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: split_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildren\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(\u001b[38;5;241m*\u001b[39msplit_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, container)\n\u001b[0;32m    105\u001b[0m     }\n\u001b[0;32m    106\u001b[0m })\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n","Cell \u001b[1;32mIn[7], line 92\u001b[0m, in \u001b[0;36mModelTree._build_tree\u001b[1;34m(self, X, y, depth, container)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_node(node, depth)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[1;32m---> 92\u001b[0m split_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m split_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdid_split\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n","Cell \u001b[1;32mIn[7], line 175\u001b[0m, in \u001b[0;36mModelTree._split_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    174\u001b[0m left_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_model(X_left, y_left)\n\u001b[1;32m--> 175\u001b[0m right_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m loss_split \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(X_left)\u001b[38;5;241m*\u001b[39mleft_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_right)\u001b[38;5;241m*\u001b[39mright_loss) \u001b[38;5;241m/\u001b[39m N\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_split \u001b[38;5;241m<\u001b[39m best_split[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","Cell \u001b[1;32mIn[7], line 112\u001b[0m, in \u001b[0;36mModelTree._fit_model\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    111\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(log_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_loss)\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_loss \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    114\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(y, preds)\n","Cell \u001b[1;32mIn[7], line 30\u001b[0m, in \u001b[0;36mLogisticRegr.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflag_y_pred \u001b[38;5;241m=\u001b[39m y_unique[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saiko\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1211\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[0;32m   1215\u001b[0m         )\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[1;32mc:\\Users\\saiko\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1224\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1221\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1223\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[1;32m-> 1224\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misspmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from sklearn.utils.fixes import loguniform\n","from sklearn.model_selection import ParameterSampler\n","from scipy.stats import randint, uniform\n","import numpy as np\n","\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('model', EnhancedModelForest(model=LogisticRegr))\n","])\n","\n","param_distributions = {\n","    'model__n_trees': randint(5, 21),\n","    'model__max_depth': randint(3, 10),\n","    'model__min_samples_leaf': randint(5, 20),\n","    'model__boosting': [True, False],\n","    'model__learning_rate': uniform(0.01, 0.5),\n","    'model__log_loss': [True, False]\n","}\n","\n","n_iter = 50\n","param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n","\n","best_score = -np.inf\n","best_params = None\n","best_model = None\n","report = None\n","\n","for params in param_list:\n","    pipeline.set_params(**params)\n","    pipeline.fit(X_train, y_train)\n","    preds = pipeline.predict(X_test)\n","    score = accuracy_score(y_test, preds)\n","\n","    if score > best_score:\n","        best_score = score\n","        best_params = params\n","        best_model = pipeline\n","        report = classification_report(y_test, preds)\n","\n","print(\"\\nBest parameters found:\")\n","print(best_params)\n","\n","print(\"\\nTest accuracy:\")\n","print(best_score)\n","\n","print(report)\n"]},{"cell_type":"code","execution_count":null,"id":"d01971fa","metadata":{"id":"d01971fa"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from sklearn.utils.fixes import loguniform\n","from sklearn.model_selection import ParameterSampler\n","from scipy.stats import randint, uniform\n","import numpy as np\n","\n","# Assume EnhancedModelForest and LogisticRegr are defined\n","# pipeline: scaler -> model\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('model', EnhancedModelForest(model=LogisticRegr))\n","])\n","\n","# Define search space\n","param_distributions = {\n","    'model__n_trees': randint(5, 21),\n","    'model__max_depth': randint(3, 10),\n","    'model__min_samples_leaf': randint(5, 20),\n","    'model__boosting': [True, False],\n","    'model__learning_rate': uniform(0.01, 0.5),\n","    'model__log_loss': [True, False]\n","}\n","\n","# Sample parameter combinations\n","n_iter = 50\n","param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n","\n","best_score = -np.inf\n","best_params = None\n","best_model = None\n","report = None\n","\n","for params in param_list:\n","    pipeline.set_params(**params)\n","    pipeline.fit(X_train, y_train)\n","    preds = pipeline.predict(X_test)\n","    score = accuracy_score(y_test, preds)\n","\n","    if score > best_score:\n","        best_score = score\n","        best_params = params\n","        best_model = pipeline\n","        report = classification_report(y_test, preds)\n","\n","print(\"\\nBest parameters found:\")\n","print(best_params)\n","\n","print(f\"\\nTest accuracy: {best_score}\")\n","\n","print(report)\n"]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","import numpy as np\n","\n","# Define both parameter sets\n","param_sets = [\n","    {'model__boosting': False, 'model__learning_rate': 0.026525366450274195,\n","     'model__log_loss': False, 'model__max_depth': 3, 'model__min_samples_leaf': 5, 'model__n_trees': 7},\n","\n","    {'model__boosting': False, 'model__learning_rate': 0.01703991135754223,\n","     'model__log_loss': True, 'model__max_depth': 3, 'model__min_samples_leaf': 12, 'model__n_trees': 7}\n","]\n","\n","for i, params in enumerate(param_sets, start=1):\n","    pipeline = Pipeline([\n","        ('scaler', StandardScaler()),\n","        ('model', EnhancedModelForest(model=LogisticRegr))\n","    ])\n","\n","    pipeline.set_params(**params)\n","    pipeline.fit(X_train, y_train)\n","    preds = pipeline.predict(X_test)\n","    acc = accuracy_score(y_test, preds)\n","    report = classification_report(y_test, preds)\n","\n","    print(f\"\\n--- Results for Param Set {i} ---\")\n","    print(f\"Parameters: {params}\")\n","    print(f\"Accuracy: {acc:.4f}\")\n","    print(\"Classification Report:\")\n","    print(report)\n"],"metadata":{"id":"PGM6MnKSTDTK"},"id":"PGM6MnKSTDTK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from sklearn.utils.fixes import loguniform\n","from sklearn.model_selection import ParameterSampler\n","from scipy.stats import randint, uniform\n","import numpy as np\n","\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('model', EnhancedModelForest(model=LogisticRegr))\n","])\n","\n","param_distributions = {\n","    'model__n_trees': randint(6, 9),  # zoom around 7\n","    'model__max_depth': [3],          # fixed at 3 (both sets agreed)\n","    'model__min_samples_leaf': randint(4, 14),  # range between 512 with buffer\n","    'model__boosting': [False],       # only False performed well\n","    'model__learning_rate': uniform(0.015, 0.015),  # zoom in around 0.0170.0265\n","    'model__log_loss': [True, False]  # both worked, test again\n","}\n","\n","\n","# Sample parameter combinations\n","n_iter = 50\n","param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n","\n","best_score = -np.inf\n","best_params = None\n","best_model = None\n","report = None\n","\n","for params in param_list:\n","    pipeline.set_params(**params)\n","    pipeline.fit(X_train, y_train)\n","    preds = pipeline.predict(X_test)\n","    score = accuracy_score(y_test, preds)\n","\n","    if score > best_score:\n","        best_score = score\n","        best_params = params\n","        best_model = pipeline\n","        report = classification_report(y_test, preds)\n","\n","print(\"\\nBest parameters found:\")\n","print(best_params)\n","\n","print(f\"\\nTest accuracy: {best_score}\")\n","\n","print(report)\n"],"metadata":{"id":"zWbR1zUzTGYp"},"id":"zWbR1zUzTGYp","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}